{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\omsur\\OneDrive\\Documents\\Python\\OKLB\\OKLB_EVN\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import aspose.words as aw\n",
    "import spacy\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the PDF document from the disc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = aw.Document(\"./r2.docx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = doc.to_string(aw.SaveFormat.TEXT)\n",
    "resume = resume.replace(\"Evaluation Only. Created with Aspose.Words. Copyright 2003-2022 Aspose Pty Ltd.\",'')\n",
    "resume = resume.replace(\"Created with an evaluation copy of Aspose.Words. To discover the full versions of our APIs please visit: https://products.aspose.com/words/\",'')\n",
    "resume = resume.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7. Your client is upset with you for a mistake you made, how do you react?\\n', 'Acknowledge their pain - empathize with them. Then apologize and offer a solution to fix the mistake.\\n']\n",
      "\n",
      "[\"98. What's the most rewarding work you've ever done and why?\\n\", \"Companies love it when you discuss how you've made an impact on your teammates, clients, or partners in the business or in school. It should be rewarding because of the hard work and creative process that you've put into it.\\n\"]\n",
      "\n",
      "['382. How do you motivate people?\\n', 'Understand their goals and needs. Align the vision of the work to their goals. Inspire them through a speech or by example.\\n']\n",
      "\n",
      "['397. Your company just had a security breach and 50,000 customer credit cards were stolen, how do you handle the situation?\\n', 'Find out what the best solution is that will protect your customers. Immediately find out who the 50,000 customers were. From there, issue a notice detailing what happened and explain what you are doing to remedy the solution (which should be implemented immediately). Offer free credit protection services to the customers.\\n']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total = []\n",
    "\n",
    "with open(\"./type1.csv\", 'r') as file:\n",
    "    csvreader = list(csv.reader(file))\n",
    "    total.append(csvreader[random.randint(0,len(csvreader)-1)])\n",
    "with open(\"./type2.csv\", 'r') as file:\n",
    "    csvreader = list(csv.reader(file))\n",
    "    total.append(csvreader[random.randint(0,len(csvreader)-1)])\n",
    "with open(\"./type3.csv\", 'r') as file:\n",
    "    csvreader = list(csv.reader(file))\n",
    "    total.append(csvreader[random.randint(0,len(csvreader)-1)])\n",
    "with open(\"./type4.csv\", 'r') as file:\n",
    "    csvreader = list(csv.reader(file))\n",
    "    total.append(csvreader[random.randint(0,len(csvreader)-1)])\n",
    "\n",
    "for row in total:\n",
    "    print(row)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_res = []\n",
    "res = [\n",
    "    \"Example stories could be a class project, an internal meeting presentation, or a customer facing presentation.\\n\",\n",
    "\n",
    "\"Don't say anything bad about the company. Did you like your job and you didn't want to move up? Did your company have a tight budget and rarely gave increases to anyone? Was your rank level a broad range so that you really did move within it, but on paper it isn't as noticeable?\\n\",\n",
    "\n",
    "\"Discuss the specific software that you use that pertains to your vertical. For example, you would use CAD in design.\\n\",\n",
    "\n",
    "\"Take the time to visualize the shoe first. Then as you go through the process make sure you describe it step by step in great detail.\\n\"]\n",
    "\n",
    "for i in range(len(total)):\n",
    "    ans_res.append([nlp(total[i][1]),nlp(res[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8307286969291328\n",
      "0.8733212554363285\n",
      "0.8552605161638749\n",
      "0.9073686087794001\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ans_res)):\n",
    "    print(ans_res[i][0].similarity(ans_res[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\omsur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from Questgen import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "            \"input_text\": resume\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model for generation\n",
      "{'questions': [{'Question': 'What is the best tool to develop a text compressor using?', 'Answer': 'django', 'id': 1, 'context': 'Vaishnavi Narkhede                                                          \\r\\n\\r\\n Vaishnavi.narkhede20@vit.edu |   +91-9356188686 |   Pune, India |  Profile Link | \\r\\n\\t\\t\\t\\t\\r\\n\\r\\nEDUCATION \\r\\n \\r\\nCourse\\rInstitute\\rBoard/University\\rYear \\rScore\\rArtificial Intelligence and Data Science Sem IV\\rVishwakarma Institute of Technology\\rAutonomous\\r2020 - Present\\r9.34\\r12th\\rNutan Junior College, Malkapur\\rState Board\\r2020\\r88%\\r10th\\rGovind Vishnu Mahajan Vidyalaya, Malkapur\\rState Board\\r2018\\r97%\\r\\r\\nSKILLS\\r\\nC/C++\\rPython\\rJava\\rDjango\\r\\r\\r    \\r\\r\\r\\r\\nINTERNSHIP\\r\\n\\r\\nAarshiti Group Web - Intern\\t\\t\\t\\t\\t\\t\\t\\t                 Sep ’21 – Jan’22\\r\\nPrototyped and developed a blogging website to share career-related opportunities using HTML, CSS, JavaScript, Django, SQLite\\r\\nCreated database and worked on the Database Modelling\\r\\n\\r\\nACADEMIC PROJECTS\\r\\n\\r\\nAR VR Research Project\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tJun’ 21 to Aug’ 21\\r\\nResearched the use cases and advantages of using AR VR in domains like Education (Biology) and Military. Vaishnavi Narkhede                                                          \\r\\n\\r\\n Vaishnavi.narkhede20@vit.edu |   +91-9356188686 |   Pune, India |  Profile Link | \\r\\n\\t\\t\\t\\t\\r\\n\\r\\nEDUCATION \\r\\n \\r\\nCourse\\rInstitute\\rBoard/University\\rYear \\rScore\\rArtificial Intelligence and Data Science Sem IV\\rVishwakarma Institute of Technology\\rAutonomous\\r2020 - Present\\r9.34\\r12th\\rNutan Junior College, Malkapur\\rState Board\\r2020\\r88%\\r10th\\rGovind Vishnu Mahajan Vidyalaya, Malkapur\\rState Board\\r2018\\r97%\\r\\r\\nSKILLS\\r\\nC/C++\\rPython\\rJava\\rDjango\\r\\r\\r    \\r\\r\\r\\r\\nINTERNSHIP\\r\\n\\r\\nAarshiti Group Web - Intern\\t\\t\\t\\t\\t\\t\\t\\t                 Sep ’21 – Jan’22\\r\\nPrototyped and developed a blogging website to share career-related opportunities using HTML, CSS, JavaScript, Django, SQLite\\r\\nCreated database and worked on the Database Modelling\\r\\n\\r\\nACADEMIC PROJECTS\\r\\n\\r\\nAR VR Research Project\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tJun’ 21 to Aug’ 21\\r\\nResearched the use cases and advantages of using AR VR in domains like Education (Biology) and Military. Zipper\\t\\t\\t\\t\\t\\t\\t\\t\\t                                          Sep’ 21 to Jan’ 21\\r\\nDeveloped a text compressor using Huffman coding, max heaps and priority queues \\r\\nIntegrated with Django for developing a web application for the ease of the user.'}, {'Question': 'Who taught 500+ women and senior citizens pan India to use apps like Google Pay, YouTube, MS Word, MS PowerPoint etc.?', 'Answer': 'college students', 'id': 2, 'context': 'Social Welfare and Development Committee\\t\\t\\t\\t\\t\\tAug ’16 – Present\\r\\nDesigned and developed a curriculum in 3 languages for a Digital Literacy program Aatmabodh, where college students taught 500+ women and senior citizens pan India to use apps like Google Pay, YouTube, MS Word, MS PowerPoint etc. VishwaSocial\\t\\t\\t\\t\\t\\t\\t\\t\\t                            Sep’ 21 to Present\\r\\nDeveloping a collaborative learning platform for college students, teachers, and alumni to network, learn new skills, and exchange opportunities. Planned, organized and moderated an event, where college alumni shared their professional journey and inspire college students to encash better career opportunities.'}, {'Question': 'What is the year of the Vishwakarma Institute of Technology Autonomous 2020 - Present?', 'Answer': 'sep', 'id': 3, 'context': 'Vaishnavi Narkhede                                                          \\r\\n\\r\\n Vaishnavi.narkhede20@vit.edu |   +91-9356188686 |   Pune, India |  Profile Link | \\r\\n\\t\\t\\t\\t\\r\\n\\r\\nEDUCATION \\r\\n \\r\\nCourse\\rInstitute\\rBoard/University\\rYear \\rScore\\rArtificial Intelligence and Data Science Sem IV\\rVishwakarma Institute of Technology\\rAutonomous\\r2020 - Present\\r9.34\\r12th\\rNutan Junior College, Malkapur\\rState Board\\r2020\\r88%\\r10th\\rGovind Vishnu Mahajan Vidyalaya, Malkapur\\rState Board\\r2018\\r97%\\r\\r\\nSKILLS\\r\\nC/C++\\rPython\\rJava\\rDjango\\r\\r\\r    \\r\\r\\r\\r\\nINTERNSHIP\\r\\n\\r\\nAarshiti Group Web - Intern\\t\\t\\t\\t\\t\\t\\t\\t                 Sep ’21 – Jan’22\\r\\nPrototyped and developed a blogging website to share career-related opportunities using HTML, CSS, JavaScript, Django, SQLite\\r\\nCreated database and worked on the Database Modelling\\r\\n\\r\\nACADEMIC PROJECTS\\r\\n\\r\\nAR VR Research Project\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tJun’ 21 to Aug’ 21\\r\\nResearched the use cases and advantages of using AR VR in domains like Education (Biology) and Military. Zipper\\t\\t\\t\\t\\t\\t\\t\\t\\t                                          Sep’ 21 to Jan’ 21\\r\\nDeveloped a text compressor using Huffman coding, max heaps and priority queues \\r\\nIntegrated with Django for developing a web application for the ease of the user. VishwaSocial\\t\\t\\t\\t\\t\\t\\t\\t\\t                            Sep’ 21 to Present\\r\\nDeveloping a collaborative learning platform for college students, teachers, and alumni to network, learn new skills, and exchange opportunities.'}]}\n"
     ]
    }
   ],
   "source": [
    "qg = main.QGen()\n",
    "output = qg.predict_shortq(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_list = []\n",
    "\n",
    "for i in output['questions']:\n",
    "    ques_list.append(i['Question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = main.AnswerPredictor()\n",
    "payload_ques = ''\n",
    "payload3 = {\n",
    "    \"input_text\" : resume,\n",
    "    \"input_question\" : payload_ques\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (885 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (899 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (893 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "ans_list = []\n",
    "\n",
    "for i in ques_list:\n",
    "    payload3['input_question'] = i\n",
    "    output = answer.predict_answer(payload3)\n",
    "    ans_list.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ques:  What is the best tool to develop a text compressor using?\n",
      "ans : Huffman coding, max heaps and priority queues integrated with django for developing a web application for the ease of the user.\n",
      "\n",
      "ques:  Who taught 500+ women and senior citizens pan India to use apps like Google Pay, YouTube, MS Word, MS PowerPoint etc.?\n",
      "ans : Aatmabodh\n",
      "\n",
      "ques:  What is the year of the Vishwakarma Institute of Technology Autonomous 2020 - Present?\n",
      "ans : Vishwakarma institute of technology autonomous 2020 is the year of the vishwakarma institute of technology autonomous 2020.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ques_list)):\n",
    "    print(\"ques: \",ques_list[i])\n",
    "    print(\"ans :\",ans_list[i])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('OKLB_EVN': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab9c5b8c8eb72cf9c87ded10c3e07204bfa944f060751a931182f72c4c3618ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
